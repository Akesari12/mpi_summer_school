{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.wcdjnk7yvmpzq2me2zzhjjrj3jikndb7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# import libraries used in this notebook\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "%matplotlib inline\n",
    "\n",
    "from string import punctuation\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import gensim\n",
    "# from gensim import models\n",
    "# from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import utils\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work in teams of 3-4. Your ultimate goal will be to predict whether a complaint is talking about a vehicle loan or student loan. Combine our workflows from both day 1 and day 2 to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfpb = pd.read_csv('data/CFPB Complaints 2023.csv')\n",
    "\n",
    "#url = 'https://github.com/Akesari12/mpi_summer_school/raw/main/data/CFPB%20Complaints%202023.csv'\n",
    "\n",
    "#cfpb = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vehicle loan or lease    4859\n",
       "Student loan             1984\n",
       "Name: Product, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cfpb['Product'].unique()\n",
    "cfpb = cfpb[cfpb['Product'].isin(['Vehicle loan or lease', 'Student loan'])].reset_index(drop=True)\n",
    "cfpb = cfpb.dropna(subset=['Consumer complaint narrative']).drop('Sub-product', axis = 1).reset_index(drop=True)\n",
    "cfpb['Product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have done two things: (1) predict some outcome based on different variables (e.g. census income bracket) and (2) extract features from text, and use that to predict an outcome (e.g. product category). What happens if we combine the two?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of the target variable (`Product`). What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Preprocess non-text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process any non-text data (e.g. most data not contained in the `Consumer complaint narrative` column). Use the techniques we covered on day 1, as well as any other techniques you can find. Try asking GPT for help!\n",
    "\n",
    "Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Preprocess text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct featurization of the text. You can choose whichever method you prefer: tf-idf, word embeddings, classificaition with prompting, etc. You can shoot for the moon, but take into account some methods may not be feasible in the limited time you have. The desired outcome for this step would be the original data frame, with new text features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Non-Text Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to predict `Product` based on all features, *besides the text*. You can use any classification method you prefer from what we have covered (or otherwise). This includes hyperparameter tuning, ensembles, combinations of them etc. Feel free to use models besides those that we explicitly covered. For example, perhaps you could consider a support vector machine. Use GPT to help you here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Text Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, try to predict `Product` based *only on the text* (or rather your text-derived features). You can use any classification method you prefer from what we have covered (or otherwise) - but be consistent with step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3**: \n",
    "\n",
    "Predict `Product` based on all availabe features, *including* the text. You can use any classification method you prefer from what we have covered (or otherwise) - but be consistent with step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4**: Evaluate\n",
    "\n",
    "Evaluate and compare. which model performed better? By what margin? Why? Was text only, non-text only, or some combination the best approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Out-of-Sample Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take your best model, and predict on this out-of-sample dataset of 2024 CFPB consumer complaints. The data you are using only contains complaints through October 2023 - how confident are you that you can replicate your success? E-mail a csv with your predictions to akesari@fordham.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_of_sample_url = 'https://github.com/Akesari12/mpi_summer_school/blob/main/data/CFPB%202024%20Features.csv'\n",
    "\n",
    "#cfpb = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explored using GPT 4o-s to do some basic classification of consumer complaints. But can GPT be useful for other outcomes as well? Try taking a subset of the complaints and explore prompts to have GPT:\n",
    "\n",
    "1. Construct a summary of narratives\n",
    "2. Estimate the sentiment and objectivity of the complaints\n",
    "3. Label the narratives with different topics\n",
    "4. And anything else you can think of!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
