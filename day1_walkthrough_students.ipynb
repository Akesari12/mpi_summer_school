{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "\n",
    "In this lab, we will introduce the fundamentals of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by introducing the concept of supervised learning. We're going to work with [Census Income dataset](https://archive.ics.uci.edu/ml/datasets/Census+Income) on the UCI Machine Learning Repository. In supervised machine learning, we start with a structured dataset where each observation is a row and each variable is a column. The goal is to use a number of features (previously you might have called these \"covariates,\" \"independent variables,\" or \"regressors\") to train a model that predicts a target (previously you might have called these \"outcome variable\" or \"dependent variable\"). In this case, we will use information like age, education, and marital status to predict each person's income-bracket.\n",
    "\n",
    "First let's load the data. The data is stored in a \".data\" format so we'll use the pandas \"read_table\" method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import LabelBinarizer \n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/Akesari12/mpi_summer_school/raw/main/data/adult.data'\n",
    "\n",
    "\n",
    "# Create a list of column names, found in \"adult.names\"\n",
    "col_names = ['age', 'workclass', 'fnlwgt',\n",
    "            'education', 'education-num',\n",
    "            'marital-status', 'occupation', \n",
    "             'relationship', 'race', \n",
    "             'sex', 'capital-gain',\n",
    "            'capital-loss', 'hours-per-week',\n",
    "            'native-country', 'income-bracket']\n",
    "\n",
    "# Read table from the data folder\n",
    "census = pd.read_csv(url, sep=',', names=col_names)\n",
    "#census = pd.read_table(os.getcwd()+\"/data/adult.data\", sep = ',', names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first 5 rows\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we predict income-bracket, we need to think about a few questions.\n",
    "\n",
    "1. What features should we include?\n",
    "2. What is the best model?\n",
    "3. How do we evaluate the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's think about the features. Check the different data types in our dataset. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we pass these features into a model, we need to convert the categorical features to numerical information. Our target is also categorical, so we will need to transform that column as well. Starting with the outcome, income-bracket, use sklearn's [LabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) to convert the **income-bracket** column to a binary outcome (0 for \"<=50k\" and 1 for \">50k\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "census['income-bracket-binary'] = lb.fit_transform(census[\"income-bracket\"])\n",
    "census.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the features we will use for prediction. There are a couple of different ways we could convert our categorical features to numerical ones. One simple way to do this is to convert them into dummy variables. Use the pandas [get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) method to convert the categorical variables into dummy variables. Be sure to drop the target variable (and the one we created) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(data=census, columns=[\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all of our categorical variables have been converted. Instead of strings, we now either have a 0 or a 1 in their place, and new columns representing each category. Take a look at the shape and structure of this new dataframe compared to the original. What can you say about these two dataframes? Is there new information, or is it presented differently? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions of Dummy Dataframe are\", X.shape)\n",
    "print(\"Dimensions of the Original Dataframe are\", census.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curse of Dimensionality and Sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data preprocessing reveals two important concepts in machine learning. Namely, [**the curse of dimensionality** and **sparsity**](https://www.kaggle.com/residentmario/curse-of-dimensionality). A sparse matrix is one filled mainly with 0s, as we see above. In geometric terms, this property means that most combinations of features are totally empty. The curse of dimensionality refers to the idea that as the number of features grow, the number of observations needed to properly model predictions grows as well. The problem is that that number of observations required grows much faster than the number of features. Trading off between increasing features to improve model performance, but reducing the number of features to avoid the instability and overfitting that occurs with too few observations, is at the heart of supervised machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another key aspect of machine learning is splitting our data. In your previous statistics classes, you likely fit regression models on an entire dataset. The problem with fitting a model this way is that models will tend to perform better on the data that they are trained on, but then perform less well on out of sample data. The error in a machine learning model comes from two sources:\n",
    "\n",
    "**Bias**: Error arising from the difference between the predicted output and the actual output. High bias models tend to be too simple and **underfit** the dataset.\n",
    "\n",
    "**Variance**: Error arising from modeling the noise in the output. High variance models tend to be too complex and **overfit** the dataset.\n",
    "\n",
    "The [**bias-variance tradeoff**](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) is a fundamental concept in machine learning. The less bias in a model, the higher the variance and vice versa. [Underfitting or overfitting](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html) a model makes generalizing to new data difficult. Trading off between these two sources of error is an essential part of machine learning. Over the next few weeks, we will explore how to deal with bias-variance tradeoff in the modeling process. Today, we'll look at how our choices in the data splitting step affect bias-variance tradeoff as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Algorithms\n",
    "\n",
    "Now we will turn to **Classification** methods. Some of this might look familiar from your previous statistics courses where you fit models on binary or categorical outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that before we try to train machine learning models on a dataset like this, we need to preprocess it. Preprocess the data to get it ready for training machine learning algorithms. Then, create a dataframe, **X**, that contains all of the features, and a series, **y**, that contains the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "lb_style = LabelBinarizer()\n",
    "y = census['income-bracket-binary'] = lb_style.fit_transform(census[\"income-bracket\"])\n",
    "\n",
    "# Features\n",
    "X = census.drop(['income-bracket', 'income-bracket-binary'], axis = 1)\n",
    "X = pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Balance\n",
    "\n",
    "Before we start modeling, let's look at the distribution of the target variable. Visualize the distribution of the target variable (\"income-bracket\"). What do you notice? What do you think this pattern suggests about how easy or difficult it would be for a machine learning model to make the correct classifications?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(y, kde = False)\n",
    "ax.set_title(\"Distribution of Target Variable (Income Bracket)\")\n",
    "ax.set(xlabel='Income Bracket', ylabel='Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, machine learning models will tend to overfit the data they are trained on. As a machine learning model becomes more complex, it learns many of the idiosyncrasies in a dataset, but this tendency will mean it generalizes poorly. To assess the extent a model is prone to this problem, and make corrections, we always split our data before training our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general procedure for this is the following:\n",
    "1. Randomly divide our data set into two smaller sets: one for training and one for testing\n",
    "2. Train the data on the training set, changing our model along the way to increase accuracy\n",
    "3. Test the data's predictions using in test set.\n",
    "\n",
    "Scikit-learn's [test_train_split function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) will help here. First, separate your data into two parts: a dataframe containing the features used to make our prediction, and an array of the true targets. We already made a dataframe with our features earlier when we created dummy variables, so now we need to make a target vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, set a random seed to ensure that we all get the same results when we sample. Then, use train_test_split to create a training set that contains 80% of the original dataset and a test set with 20% of the original data. Then check the shapes of each of the new sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation set**\n",
    "\n",
    "Because we may want to adjust our models, it is generally a good idea to save the test set until the very end and only use it once. Instead of going back and forth between the training and test set, we should instead use a validation set. Try using the train_test_split method to further split your training data so that 75% remains in training and 25% is reserved for validation. Note that this will mean the final split is 60% train, 20% validation, and 20% test. Check the dimensions of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = .80, test_size=0.20,\n",
    "                                                   stratify=y)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, train_size = .75, test_size = .25, \n",
    "                                                           stratify = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [decision tree classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) is a popular classification algorithm. A tree-based classifier learns to map the features to the target by creating a series of if-then-else decision rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Akesari12/Computational-Social-Science-Training-Program/blob/master/images/iris%20tree.png?raw=true\" style=\"width: 500px; height: 275px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the following code block to create a decision tree model. Then fit it on the training data, and report the accuracy in both the train and validation sets using the \"score\" method. Check the decision tree classifier documentaiton for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt_classifier = tree.DecisionTreeClassifier(criterion='gini',  # or 'entropy' for information gain\n",
    "                       splitter='best',  # or 'random' for random best split\n",
    "                       max_depth=None,  # how deep tree nodes can go\n",
    "                       min_samples_split=2,  # samples needed to split node\n",
    "                       min_samples_leaf=1,  # samples needed for a leaf\n",
    "                       min_weight_fraction_leaf=0.0,  # weight of samples needed for a node\n",
    "                       max_features=None,  # number of features to look for when splitting\n",
    "                       max_leaf_nodes=None,  # max nodes\n",
    "                       min_impurity_decrease=1e-07, #early stopping\n",
    "                       random_state = 10) #random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_classifier.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_classifier.score(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: How does your training accuracy compare to your validation accuracy? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at a unique aspect of tree-based methods: [**feature importances**](https://kdnuggets.com/2020/02/decision-tree-intuition.html). There are a few different ways to calculate a feature importance. One way to do it is to see how much information each new feature adds. If a feature does not add any or very little information to a prediction, it may be possible to safely drop it. Use the following code to put the feature importances and features into a dataframe, then plot the 10 largest feature importances. **Hint**: Consider using the [nlargest](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.nlargest.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.concat([pd.DataFrame(X.columns),pd.DataFrame(np.transpose(dt_classifier.feature_importances_))], axis = 1)\n",
    "feat_importances.columns = [\"Feature\", \"Importance\"]\n",
    "sns.barplot(x = \"Importance\", y = \"Feature\", data = feat_importances.nlargest(10, 'Importance'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Which features are the most important? How are these values different from a regression coefficient? How do you think these can be used to explain decisions based on machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's make predictions on the validation set. Then, visualize how your predictions with a confusion matrix. Refer back to the Intro to Machine Learning Lab or the [confusion matrix documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) if you need a reminder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt_classifier.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = true doesn't work for some people\n",
    "cf_matrix = confusion_matrix(y_validate, y_pred, normalize = \"true\")\n",
    "\n",
    "df_cm = pd.DataFrame(cf_matrix, range(2),\n",
    "                  range(2))\n",
    "\n",
    "df_cm = df_cm.rename(index=str, columns={0: \"<=50k\", 1: \">50k\"})\n",
    "df_cm.index = [\"<=50k\", \">50k\"]\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, \n",
    "           annot=True,\n",
    "           annot_kws={\"size\": 16},\n",
    "           fmt='g')\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at a [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Make a logistic regression model, fit it to the training data, and predict on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "logit_reg = LogisticRegression()\n",
    "\n",
    "# fit the model\n",
    "logit_model = logit_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit_model.predict(X_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a dataframe with the features and the logit coefficients (Note: For the logit coefficients you need to use np.transpose or extract the coefficients from the 1d array). Then plot the 10 coefficients with the largest absolute value. Hint: Consider creating a new column with the absolute values for the coefficients, and then using the nlargest before plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_data = pd.concat([pd.DataFrame(X.columns),pd.DataFrame(np.transpose(logit_model.coef_))], axis = 1)\n",
    "logit_data.columns = ['Feature', 'Coefficient']\n",
    "logit_data['abs_coef'] = abs(logit_data['Coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Coefficient\", y=\"Feature\", data=logit_data.nlargest(10, 'abs_coef')).set_title(\"Top Logit Coefficients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: How do the coefficients compare to the feature importances from the decision tree? Is there overlap? Are they interpretable from a decisionmaker's perspective?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a confusion matrix to visualize how well you did with your predictions. Are there differences between this confusion matrix and the one you created for the decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we are concerned about the <b>curse of dimensionality</b>. Using either the deciion tree or logistic regression classifier, can you trained a model using fewer features than the full set? How much accuracy do you lose if any by focusing only on a few important features, or ones with large coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, choosing the optimal train/validation/test split can be difficult. It is also prone to high variance problems as the machine learning algorithm's performance will be very dependent on the composition of the randomly sampled test split. This problem is exacerbated in small datasets especially. One way to address this problem is with [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#:~:text=Cross%2Dvalidation%2C%20sometimes%20called%20rotation,to%20an%20independent%20data%20set).\n",
    "\n",
    "The general procedure is:\n",
    "\n",
    "1. Randomly split the data into k-folds\n",
    "2. Build the model on k-1 folds, then test on the last fold\n",
    "3. Record prediction error\n",
    "4. Cycle until each fold has served as the test set\n",
    "5. The average of the errors is the cv-error\n",
    "\n",
    "Cross-validation has the advantage of allowing every data point to be in the test set once. By averaging the errors, the model is less sensitive to variation in the random samples, and is less prone to overfitting. Let's try with our logistic regression again, using the [cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) method.\n",
    "\n",
    "<center>\n",
    "    <img src='https://github.com/Akesari12/CELS-ML-Text-Analysis-Workshop/blob/main/images/cross%20validation.png?raw=true'/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X = census.drop(['income-bracket'], axis=1)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Assuming 'income' has been preprocessed into 'income-bracket-binary'\n",
    "# y = (census['income'] == '>50K').astype(int)  # Example of binarization\n",
    "y = census['income-bracket-binary']\n",
    "\n",
    "# Initialize logistic regression model\n",
    "logit_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Perform cross-validated predictions\n",
    "log_pred = cross_val_predict(logit_model, X, y, cv=5)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cf_matrix = confusion_matrix(y, log_pred, normalize='true')\n",
    "\n",
    "# Create a DataFrame for the confusion matrix\n",
    "df_cm = pd.DataFrame(cf_matrix, range(2), range(2))\n",
    "df_cm = df_cm.rename(index=str, columns={0: \"<=50k\", 1: \">50k\"})\n",
    "df_cm.index = [\"<=50k\", \">50k\"]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.set(font_scale=1.4)  # for label size\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='g')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with sklearn's regression methods, we can also use [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to search for optimal hyperparameters. Choose one of the classification methods we have used so far and do a grid search to find the best hyperparameter values. **Note**: You might notice that the grid search takes a **very** long time to complete depending on the model and hyperparameters chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {...: [..., ...],\n",
    "              ...: [..., ...]}\n",
    "\n",
    "grid = GridSearchCV(..., param_grid, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_index = np.argmax(grid.cv_results_[\"mean_test_score\"])\n",
    "best_grid_pred = grid.best_estimator_.predict(X_validate)\n",
    "\n",
    "print(grid.cv_results_[\"params\"][best_index])\n",
    "print('Validation Accuracy', accuracy_score(best_grid_pred, y_validate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, accuracy isn't the only metric that we might care about. Accuracy is an expression of ratio of correct observations relative to incorrect observations. This calculation alone does not tell us much about whether we did a good job predicting all of the various categories that we might be concerned about. Consider our census dataset. We saw earlier that the target data is not equally distributed - there were far more people with \"<=50k\" income. As we saw in our confusion matrices, our algorithms tended to predict observations belonging to the \"<=50k\" category remarkably well, but tended to do much worse with the \">50k\" category. Why do you think this might be the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a few metrics that will help us move beyond accuracy as our only measure:\n",
    "\n",
    "$$\n",
    "True \\space Positives = \\sum({Predicted \\space Positives = Observed \\space Positives})\n",
    "$$\n",
    "\n",
    "$$\n",
    "False \\space Positives = \\sum({Predicted \\space Positives \\space != Observed \\space Positives})\n",
    "$$\n",
    "\n",
    "$$\n",
    "True \\space Negatives = \\sum({Predicted \\space Negatives = Observed \\space Negatives})\n",
    "$$\n",
    "\n",
    "$$\n",
    "False \\space Negatives = \\sum({Predicted \\space Negatives \\space != Observed \\space Negatives})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we were primarily interested in detecting whether someone is \">50k\". We'll call this the \"positive\" class. A \"predicted\" observation is the value the model predicted, while the \"observed\" observation is the value in the ground-truth labels. So a \"true positive\" in this case would be instances when the model predicted someone to be in the \">50k\" category AND they were in the \">50k\" category in reality. Similarly, a false positive would be instances where the model predicted someone was in the \">50k\" category when they were actually in the \"<=50k\" category in reality. Use your best model from hyperparameter to predict on the validation set and see how you did on each of these metrics. **Hint**: The confusion matrix is actually a great way to visualize all of these. What does each quadrant of the matrix correspond to in terms of these metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These metrics matter in the social sciences because we usually are not given balanced datasets, and we are oftentimes concerned with predicting rare events. Predicting rare events like fraud, credit defaults, and mortality is difficult. Optimizing on accuracy alone can be misleading if the algorithm just guesses the majority class every time without ever predicting the outcome of interest. Next week we will delve even deeper into these concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**\n",
    "\n",
    "Accuracy can be expressed as:\n",
    "\n",
    "$$\n",
    "Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "The numerator is the number of correction predictions regardless of direction, divided by the total number observations (correct predictions + incorrect predictions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision**\n",
    "  \n",
    "Precision is a measure of how well calibrated predictions are. The formula for precision is:\n",
    "\n",
    "$$\n",
    "Precision = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "This formula tell us of the predictions in the positive class (\">50k\" in this case) we made, how many were correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall**\n",
    "\n",
    "Recall is defined as:\n",
    "\n",
    "$$\n",
    "Recall = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "Of all of the positive class members in the ground truth labels, how many did we successfully predict as positive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Score**\n",
    "\n",
    "  The precision-recall tradeoff can be managed in a few different ways. One popular metric is the F1 score. It is defined as:\n",
    "\n",
    "$$\n",
    "F1 = 2 * \\frac{precision * recall}{precision + recall}\n",
    "$$\n",
    "\n",
    "F1 is advantageous because the numerator can be penalized by either low precision OR recall. The disadvantage of this approach is that without adjustments, the F1 score prioritizes precision and recall equally. Depending on the application, we might care about one more than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUC-ROC**\n",
    "\n",
    "[Area Under the Curve - Receiver Operating Characteristic (AUC-ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) is a popular method for seeing how well an algorithm does at separating between two classes. It is calculated by plotting the True Positive Rate against the False Positive Rate. Let's define these quantities:\n",
    "\n",
    "$$\n",
    "True \\space Positive \\space Rate(TPR) = Sensitivity = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "Hm, this formula looks familiar. In fact, it is exactly the same as Recall! Meanwhile, the False Positive Rate is:\n",
    "\n",
    "$$\n",
    "False \\space Positive \\space Rate (FPR) = 1 - Specificity = \\frac{FP}{TN + FP}\n",
    "$$\n",
    "\n",
    "By comparing TPR to FPR, we can see how well a model does at detecting the positive class. A TPR of 1 and a FPR of 0 would imply that the model does a perfect job at classifying positives as positives and negatives as negatives. It basically contextualizes Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(y_pred)): \n",
    "    if y_validate[i]==y_pred[i]==1:\n",
    "       TP += 1\n",
    "    if y_pred[i]==1 and y_validate[i]!=y_pred[i]:\n",
    "       FP += 1\n",
    "    if y_validate[i]==y_pred[i]==0:\n",
    "       TN += 1\n",
    "    if y_pred[i]==0 and y_pred[i]!=y_validate[i]:\n",
    "       FN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "precision = TP/(TP + FP)\n",
    "recall = TP/(TP + FN)\n",
    "f1 = 2 * (precision * recall)/(precision + recall)\n",
    "print(\"Accuracy is\", round(accuracy,3))\n",
    "print(\"Precision is\", round(precision,3))\n",
    "print(\"Recall is\", round(recall,3))\n",
    "print(\"F1 Score is\", round(f1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "\n",
    "# split into train/test sets\n",
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_validate))]\n",
    "\n",
    "\n",
    "# predict probabilities for logistic regression\n",
    "lr_probs = logit_model.predict_proba(X_validate)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(y_validate, ns_probs)\n",
    "lr_auc = roc_auc_score(y_validate, lr_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_validate, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_validate, lr_probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over and Under Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that imbalanced data can cause all sorts of problems and give us misleading results, especially if we only focus on accuracy. How can we correct for these problems? One simple method is to **resample** the data. For example, you might **oversample** the minority class or **undersample** the majority class. Let's use the [**imblearn**](https://imbalanced-learn.readthedocs.io/en/stable/api.html) to try this out. First, you might need to run the cell below to install the library. Anytime you use \"!\" in a Jupyter notebook, this will actually run a bash command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import the RandomOverSampler and RandomUnderSampler methods. Then take a look at the first 15 values in y_train before we resample.\n",
    "\n",
    "Why would we resample the training set, instead of the dataset or the validation/test sets?\n",
    "We want our evaluations to be as close to reality as possible. If the actual social science or policy problem has imbalanced class labels, we don't want to make an algorithm look artificially good by validating and testing in a resampled dataset that does not resemble the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "random_over_sampler = RandomOverSampler(sampling_strategy=0.5)\n",
    "random_under_sampler = RandomUnderSampler(sampling_strategy=0.5)\n",
    "\n",
    "X_train_new, y_train_new = random_under_sampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain the logistic regression model on the newly resampled data. How does AUC-ROC change? Play around with different resampling values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "logit_model = ...\n",
    "\n",
    "y_pred = logit_model.predict(...)\n",
    "\n",
    "# roc curve and auc\n",
    "\n",
    "# split into train/test sets\n",
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_validate))]\n",
    "\n",
    "\n",
    "# predict probabilities for logistic regression\n",
    "lr_probs = logit_model.predict_proba(X_validate)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(y_validate, ns_probs)\n",
    "lr_auc = roc_auc_score(y_validate, lr_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_validate, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_validate, lr_probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, while sklearn puts together many of the methods we need to train, predict, and visualize the results of our machine learning, there are a lot of substantive choices involved. As you can see, even a slightly imbalanced dataset can cause problems. If you optimize only on accuracy, you might miss relevant aspects of the problem. Be mindful of the various metrics available, and decide which ones best answer the scientific question you have in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create ensembles with algorithms beyond decision trees. Scikit's ensemble module contains several different options for training ensemble models. Here, we will focus on the [`VotingClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html) method. A voting classifier works in a similar fashion to random forest. However, instead of taking a majority vote of decision trees, it takes a majority vote of various algorithms. The voting can be \"hard\" which means the ensemble uses a majority vote of predicted classes, or \"soft\" meaning the votes are weighted by the probability associated with the prediction. Write code below to initialize a logistic regression, a random forest, and an adaboost model. Then, pass all three of these into the VotingClassifier to train an ensemble model, and check out their accuracy scores. As a bonus, try hyperparameter tuning each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83 [Logistic Regression]\n",
      "Accuracy: 0.85 [Random Forest]\n",
      "Accuracy: 0.86 [Ada Boost]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86 [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg = ...\n",
    "\n",
    "# Random Forest\n",
    "rf_classifier = ...\n",
    "\n",
    "# AdaBoost\n",
    "ada_classifier = ...\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "                        estimators = [('lr', log_reg),\n",
    "                                     ('rf', rf_classifier),\n",
    "                                     ('ada', ada_classifier)],\n",
    "                        voting = 'hard')\n",
    "\n",
    "# Loop through each model to report Accuracy\n",
    "for clf, label in zip([log_reg, \n",
    "                       rf_classifier, \n",
    "                       ada_classifier, \n",
    "                       voting_classifier], ['Logistic Regression', \n",
    "                                            'Random Forest', \n",
    "                                            'Ada Boost',\n",
    "                                            'Ensemble']):\n",
    "         scores = cross_val_score(clf, X, y.ravel(), scoring='accuracy', cv=5)\n",
    "         print('Accuracy: %0.2f [%s]' % (scores.mean(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the ensemble do? Next, try to use a soft voting classifier to get the predicted probabilities for each prediction. Try using the `predict_proba()` method to get the predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(\n",
    "                        estimators = [('lr', log_reg),\n",
    "                                     ('rf', rf_classifier),\n",
    "                                     ('ada', ada_classifier)],\n",
    "                        voting = 'soft')\n",
    "\n",
    "probas = [c.fit(X, y.ravel()).predict_proba(X)[:,1] for c in (log_reg, rf_classifier, ada_classifier, voting_classifier)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put our predicted probabilities into a dataframe so we can visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logit</th>\n",
       "      <th>rf</th>\n",
       "      <th>ada</th>\n",
       "      <th>ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.113884</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.492965</td>\n",
       "      <td>0.207838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.697814</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.499728</td>\n",
       "      <td>0.449181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490396</td>\n",
       "      <td>0.171400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.236171</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.493518</td>\n",
       "      <td>0.246563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.710478</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.498092</td>\n",
       "      <td>0.509523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.601630</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.503048</td>\n",
       "      <td>0.466559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.062962</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.484238</td>\n",
       "      <td>0.185733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.395481</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.501082</td>\n",
       "      <td>0.615521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.775731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.515062</td>\n",
       "      <td>0.763598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.872011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509004</td>\n",
       "      <td>0.793672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      logit        rf       ada  ensemble\n",
       "0  0.113884  0.016667  0.492965  0.207838\n",
       "1  0.697814  0.150000  0.499728  0.449181\n",
       "2  0.023804  0.000000  0.490396  0.171400\n",
       "3  0.236171  0.010000  0.493518  0.246563\n",
       "4  0.710478  0.320000  0.498092  0.509523\n",
       "5  0.601630  0.295000  0.503048  0.466559\n",
       "6  0.062962  0.010000  0.484238  0.185733\n",
       "7  0.395481  0.950000  0.501082  0.615521\n",
       "8  0.775731  1.000000  0.515062  0.763598\n",
       "9  0.872011  1.000000  0.509004  0.793672"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_df = pd.DataFrame.from_records(probas).T\n",
    "probs_df.rename(columns = {0: 'logit',\n",
    "                          1: 'rf',\n",
    "                          2: 'ada',\n",
    "                          3: 'ensemble'}, inplace = True)\n",
    "probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "sns.histplot(probs_df, x = \"logit\", ax = ax)\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "sns.histplot(probs_df, x = \"rf\", ax = ax)\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "sns.histplot(probs_df, x = \"ada\", ax = ax)\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "sns.histplot(probs_df, x = \"ensemble\", ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What do you notice about the distribution of the predicted probabilities? Do these make sense given what you know about the models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
